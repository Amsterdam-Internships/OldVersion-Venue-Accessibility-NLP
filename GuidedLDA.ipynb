{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a13b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc386bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import guidedlda as glda\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540c2f7",
   "metadata": {},
   "source": [
    "## Reading and Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15256cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/k7vf4gp97fb11dzjbcr7w8bc0000gn/T/ipykernel_76613/686763101.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1=pd.read_csv(\"./Data/train_data.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Sent</th>\n",
       "      <th>Text</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Term3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>10</td>\n",
       "      <td>coffeeshop la grotte</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>2nd year coming here and can t say enough good...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373579</th>\n",
       "      <td>451</td>\n",
       "      <td>pata negra</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128693</th>\n",
       "      <td>112</td>\n",
       "      <td>bagels &amp; beans ijdock</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>location, very nice and welcoming, with a spl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120681</th>\n",
       "      <td>17</td>\n",
       "      <td>plum</td>\n",
       "      <td>2020</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>went to this place on saturday. i had the gril...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162003</th>\n",
       "      <td>504</td>\n",
       "      <td>caf‚àö¬© thijssen</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>was wer very tasty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Venue Index                   Name  Date     Rating Rating Sent  \\\n",
       "Index                                                                     \n",
       "18594            10   coffeeshop la grotte  2019   5 stars     positive   \n",
       "373579          451             pata negra  2019   5 stars     positive   \n",
       "128693          112  bagels & beans ijdock  2021   5 stars     positive   \n",
       "120681           17                   plum  2020   5 stars     positive   \n",
       "162003          504      caf‚àö¬© thijssen  2021   5 stars     positive   \n",
       "\n",
       "                                                     Text  Aspect  \\\n",
       "Index                                                               \n",
       "18594   2nd year coming here and can t say enough good...       0   \n",
       "373579                                          excellent       0   \n",
       "128693   location, very nice and welcoming, with a spl...       0   \n",
       "120681  went to this place on saturday. i had the gril...       0   \n",
       "162003                                 was wer very tasty       0   \n",
       "\n",
       "        Accessibility Term1 Term2 Term3  \n",
       "Index                                    \n",
       "18594               0   NaN   NaN   NaN  \n",
       "373579              0   NaN   NaN   NaN  \n",
       "128693              0   NaN   NaN   NaN  \n",
       "120681              0   NaN   NaN   NaN  \n",
       "162003              0   NaN   NaN   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"./Data/train_data.csv\")\n",
    "df1 = df1.set_index(\"Index\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b8b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "punctuations = list(set(string.punctuation))\n",
    "unwanted_list=punctuations+stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b28bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_strings(text):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    \n",
    "    return text\n",
    "    \n",
    "def tokenize(text):\n",
    "    text = ' '.join([x.lower() for x in word_tokenize(text) if x.lower() not in unwanted_list and len(x)>1])\n",
    "    text = ' '.join([x.lower() for x in word_tokenize(text) if nltk.pos_tag([x])[0][1].startswith(\"NN\") or nltk.pos_tag([x])[0][1].startswith(\"JJ\")])\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e66e4465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 13.7 ms, total: 244 ms\n",
      "Wall time: 254 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Sent</th>\n",
       "      <th>Text</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Term3</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>10</td>\n",
       "      <td>coffeeshop la grotte</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>nd year coming here and can t say enough good...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nd year coming here and can t say enough good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373579</th>\n",
       "      <td>451</td>\n",
       "      <td>pata negra</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128693</th>\n",
       "      <td>112</td>\n",
       "      <td>bagels &amp; beans ijdock</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>location  very nice and welcoming  with a spl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location  very nice and welcoming  with a spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120681</th>\n",
       "      <td>17</td>\n",
       "      <td>plum</td>\n",
       "      <td>2020</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>went to this place on saturday  i had the gril...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>went to this place on saturday  i had the gril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162003</th>\n",
       "      <td>504</td>\n",
       "      <td>caf‚àö¬© thijssen</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>was wer very tasty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>was wer very tasty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Venue Index                   Name  Date     Rating Rating Sent  \\\n",
       "Index                                                                     \n",
       "18594            10   coffeeshop la grotte  2019   5 stars     positive   \n",
       "373579          451             pata negra  2019   5 stars     positive   \n",
       "128693          112  bagels & beans ijdock  2021   5 stars     positive   \n",
       "120681           17                   plum  2020   5 stars     positive   \n",
       "162003          504      caf‚àö¬© thijssen  2021   5 stars     positive   \n",
       "\n",
       "                                                     Text  Aspect  \\\n",
       "Index                                                               \n",
       "18594    nd year coming here and can t say enough good...       0   \n",
       "373579                                          excellent       0   \n",
       "128693   location  very nice and welcoming  with a spl...       0   \n",
       "120681  went to this place on saturday  i had the gril...       0   \n",
       "162003                                 was wer very tasty       0   \n",
       "\n",
       "        Accessibility Term1 Term2 Term3  \\\n",
       "Index                                     \n",
       "18594               0   NaN   NaN   NaN   \n",
       "373579              0   NaN   NaN   NaN   \n",
       "128693              0   NaN   NaN   NaN   \n",
       "120681              0   NaN   NaN   NaN   \n",
       "162003              0   NaN   NaN   NaN   \n",
       "\n",
       "                                               clean_text  \n",
       "Index                                                      \n",
       "18594    nd year coming here and can t say enough good...  \n",
       "373579                                          excellent  \n",
       "128693   location  very nice and welcoming  with a spl...  \n",
       "120681  went to this place on saturday  i had the gril...  \n",
       "162003                                 was wer very tasty  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df1[\"clean_text\"]=df1['Text'].apply(lambda text:clean_strings(str(text)))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc1d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 38s, sys: 1min 20s, total: 15min 59s\n",
      "Wall time: 17min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Sent</th>\n",
       "      <th>Text</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Accessibility</th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Term3</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>10</td>\n",
       "      <td>coffeeshop la grotte</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>nd year coming here and can t say enough good...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nd year good things place great staff food won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373579</th>\n",
       "      <td>451</td>\n",
       "      <td>pata negra</td>\n",
       "      <td>2019</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128693</th>\n",
       "      <td>112</td>\n",
       "      <td>bagels &amp; beans ijdock</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>location  very nice and welcoming  with a spl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location nice splendid view large water channe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120681</th>\n",
       "      <td>17</td>\n",
       "      <td>plum</td>\n",
       "      <td>2020</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>went to this place on saturday  i had the gril...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>place saturday cheese minute drive drive worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162003</th>\n",
       "      <td>504</td>\n",
       "      <td>caf‚àö¬© thijssen</td>\n",
       "      <td>2021</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>positive</td>\n",
       "      <td>was wer very tasty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wer tasty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Venue Index                   Name  Date     Rating Rating Sent  \\\n",
       "Index                                                                     \n",
       "18594            10   coffeeshop la grotte  2019   5 stars     positive   \n",
       "373579          451             pata negra  2019   5 stars     positive   \n",
       "128693          112  bagels & beans ijdock  2021   5 stars     positive   \n",
       "120681           17                   plum  2020   5 stars     positive   \n",
       "162003          504      caf‚àö¬© thijssen  2021   5 stars     positive   \n",
       "\n",
       "                                                     Text  Aspect  \\\n",
       "Index                                                               \n",
       "18594    nd year coming here and can t say enough good...       0   \n",
       "373579                                          excellent       0   \n",
       "128693   location  very nice and welcoming  with a spl...       0   \n",
       "120681  went to this place on saturday  i had the gril...       0   \n",
       "162003                                 was wer very tasty       0   \n",
       "\n",
       "        Accessibility Term1 Term2 Term3  \\\n",
       "Index                                     \n",
       "18594               0   NaN   NaN   NaN   \n",
       "373579              0   NaN   NaN   NaN   \n",
       "128693              0   NaN   NaN   NaN   \n",
       "120681              0   NaN   NaN   NaN   \n",
       "162003              0   NaN   NaN   NaN   \n",
       "\n",
       "                                               clean_text  \n",
       "Index                                                      \n",
       "18594   nd year good things place great staff food won...  \n",
       "373579                                          excellent  \n",
       "128693  location nice splendid view large water channe...  \n",
       "120681  place saturday cheese minute drive drive worth...  \n",
       "162003                                          wer tasty  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df1[\"clean_text\"]=df1['Text'].apply(lambda text:tokenize(str(text)))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46d7746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subset of reviews discussing accessibility\n",
    "df2 = df1[df1[\"Accessibility\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04078fde",
   "metadata": {},
   "source": [
    "## Creating objects required for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91fc2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=df2.clean_text.tolist()\n",
    "vocab=list(set(word_tokenize(\" \".join(df2.clean_text))))\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1),vocabulary=vocab)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word2id=vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756e231",
   "metadata": {},
   "source": [
    "## Defining priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f95d6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_acc_words=[\"disability\",\"disabled\",\"handicap\",\"handicapped\",\"wheelchair\",\"stroller\",\n",
    "             \"mobility\",\"reduced mobility\"]\n",
    "\n",
    "entrance_words=[\"ramp\",\"entrance\",\"wide\",\"narrow\",\"door\"]\n",
    "\n",
    "bathroom_words=[\"bathroom\",\"toilet\",\"restroom\",\"handrail\"]\n",
    "\n",
    "space_words=[\"spacious\",\"space\",\"cramped\",\"small\",\"large\",\"seating\",\"room\"]\n",
    "\n",
    "stairs_words=[\"stair\",\"stairs\",\"steps\",\"step\",\"elevator\",\"staircase\",\"narrow\",\"tricky\",\"steep\",\"handrail\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac1671",
   "metadata": {},
   "source": [
    "## Removing prior words that are not part of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe15044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_acc_words = [x for x in general_acc_words if x in list(word2id.keys())]\n",
    "entrance_words = [x for x in entrance_words if x in list(word2id.keys())]\n",
    "bathroom_words = [x for x in bathroom_words if x in list(word2id.keys())]\n",
    "space_words = [x for x in space_words if x in list(word2id.keys())]\n",
    "stairs_words = [x for x in stairs_words if x in list(word2id.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871ac1d",
   "metadata": {},
   "source": [
    "## Creating list of word lists as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fab21973",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topic_list = [\n",
    "    general_acc_words,\n",
    "    entrance_words,\n",
    "    bathroom_words,\n",
    "    space_words,\n",
    "    stairs_words\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c738b2",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ce7906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = glda.GuidedLDA(n_topics=5, n_iter=2000, random_state=7, refresh=20,alpha=0.01,eta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad14cdb",
   "metadata": {},
   "source": [
    "## Setting priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40b8bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        seed_topics[word2id[word]] = t_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2cc38",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "303eec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 1720\n",
      "INFO:guidedlda:vocab_size: 3085\n",
      "INFO:guidedlda:n_words: 20416\n",
      "INFO:guidedlda:n_topics: 5\n",
      "INFO:guidedlda:n_iter: 2000\n",
      "INFO:guidedlda:<0> log likelihood: -211686\n",
      "INFO:guidedlda:<20> log likelihood: -153305\n",
      "INFO:guidedlda:<40> log likelihood: -151257\n",
      "INFO:guidedlda:<60> log likelihood: -150799\n",
      "INFO:guidedlda:<80> log likelihood: -150115\n",
      "INFO:guidedlda:<100> log likelihood: -149746\n",
      "INFO:guidedlda:<120> log likelihood: -149317\n",
      "INFO:guidedlda:<140> log likelihood: -149204\n",
      "INFO:guidedlda:<160> log likelihood: -148742\n",
      "INFO:guidedlda:<180> log likelihood: -148614\n",
      "INFO:guidedlda:<200> log likelihood: -148295\n",
      "INFO:guidedlda:<220> log likelihood: -148233\n",
      "INFO:guidedlda:<240> log likelihood: -148100\n",
      "INFO:guidedlda:<260> log likelihood: -148001\n",
      "INFO:guidedlda:<280> log likelihood: -147951\n",
      "INFO:guidedlda:<300> log likelihood: -148191\n",
      "INFO:guidedlda:<320> log likelihood: -147736\n",
      "INFO:guidedlda:<340> log likelihood: -147838\n",
      "INFO:guidedlda:<360> log likelihood: -147865\n",
      "INFO:guidedlda:<380> log likelihood: -147728\n",
      "INFO:guidedlda:<400> log likelihood: -147482\n",
      "INFO:guidedlda:<420> log likelihood: -147580\n",
      "INFO:guidedlda:<440> log likelihood: -147412\n",
      "INFO:guidedlda:<460> log likelihood: -147583\n",
      "INFO:guidedlda:<480> log likelihood: -147494\n",
      "INFO:guidedlda:<500> log likelihood: -147445\n",
      "INFO:guidedlda:<520> log likelihood: -147429\n",
      "INFO:guidedlda:<540> log likelihood: -147426\n",
      "INFO:guidedlda:<560> log likelihood: -147552\n",
      "INFO:guidedlda:<580> log likelihood: -147394\n",
      "INFO:guidedlda:<600> log likelihood: -147140\n",
      "INFO:guidedlda:<620> log likelihood: -147281\n",
      "INFO:guidedlda:<640> log likelihood: -147278\n",
      "INFO:guidedlda:<660> log likelihood: -147126\n",
      "INFO:guidedlda:<680> log likelihood: -147308\n",
      "INFO:guidedlda:<700> log likelihood: -147124\n",
      "INFO:guidedlda:<720> log likelihood: -147025\n",
      "INFO:guidedlda:<740> log likelihood: -146839\n",
      "INFO:guidedlda:<760> log likelihood: -147062\n",
      "INFO:guidedlda:<780> log likelihood: -147144\n",
      "INFO:guidedlda:<800> log likelihood: -147093\n",
      "INFO:guidedlda:<820> log likelihood: -147205\n",
      "INFO:guidedlda:<840> log likelihood: -146978\n",
      "INFO:guidedlda:<860> log likelihood: -147126\n",
      "INFO:guidedlda:<880> log likelihood: -147108\n",
      "INFO:guidedlda:<900> log likelihood: -147062\n",
      "INFO:guidedlda:<920> log likelihood: -147070\n",
      "INFO:guidedlda:<940> log likelihood: -147070\n",
      "INFO:guidedlda:<960> log likelihood: -147017\n",
      "INFO:guidedlda:<980> log likelihood: -147070\n",
      "INFO:guidedlda:<1000> log likelihood: -146973\n",
      "INFO:guidedlda:<1020> log likelihood: -147074\n",
      "INFO:guidedlda:<1040> log likelihood: -146848\n",
      "INFO:guidedlda:<1060> log likelihood: -146886\n",
      "INFO:guidedlda:<1080> log likelihood: -146961\n",
      "INFO:guidedlda:<1100> log likelihood: -146780\n",
      "INFO:guidedlda:<1120> log likelihood: -146852\n",
      "INFO:guidedlda:<1140> log likelihood: -146702\n",
      "INFO:guidedlda:<1160> log likelihood: -146792\n",
      "INFO:guidedlda:<1180> log likelihood: -146904\n",
      "INFO:guidedlda:<1200> log likelihood: -147027\n",
      "INFO:guidedlda:<1220> log likelihood: -146873\n",
      "INFO:guidedlda:<1240> log likelihood: -146772\n",
      "INFO:guidedlda:<1260> log likelihood: -146841\n",
      "INFO:guidedlda:<1280> log likelihood: -146799\n",
      "INFO:guidedlda:<1300> log likelihood: -146686\n",
      "INFO:guidedlda:<1320> log likelihood: -146874\n",
      "INFO:guidedlda:<1340> log likelihood: -146867\n",
      "INFO:guidedlda:<1360> log likelihood: -146905\n",
      "INFO:guidedlda:<1380> log likelihood: -146974\n",
      "INFO:guidedlda:<1400> log likelihood: -146906\n",
      "INFO:guidedlda:<1420> log likelihood: -146920\n",
      "INFO:guidedlda:<1440> log likelihood: -146941\n",
      "INFO:guidedlda:<1460> log likelihood: -146744\n",
      "INFO:guidedlda:<1480> log likelihood: -146790\n",
      "INFO:guidedlda:<1500> log likelihood: -146823\n",
      "INFO:guidedlda:<1520> log likelihood: -146861\n",
      "INFO:guidedlda:<1540> log likelihood: -146814\n",
      "INFO:guidedlda:<1560> log likelihood: -146771\n",
      "INFO:guidedlda:<1580> log likelihood: -146751\n",
      "INFO:guidedlda:<1600> log likelihood: -146738\n",
      "INFO:guidedlda:<1620> log likelihood: -146938\n",
      "INFO:guidedlda:<1640> log likelihood: -146918\n",
      "INFO:guidedlda:<1660> log likelihood: -146858\n",
      "INFO:guidedlda:<1680> log likelihood: -146802\n",
      "INFO:guidedlda:<1700> log likelihood: -146942\n",
      "INFO:guidedlda:<1720> log likelihood: -146787\n",
      "INFO:guidedlda:<1740> log likelihood: -146767\n",
      "INFO:guidedlda:<1760> log likelihood: -146682\n",
      "INFO:guidedlda:<1780> log likelihood: -146778\n",
      "INFO:guidedlda:<1800> log likelihood: -146690\n",
      "INFO:guidedlda:<1820> log likelihood: -146837\n",
      "INFO:guidedlda:<1840> log likelihood: -146741\n",
      "INFO:guidedlda:<1860> log likelihood: -146909\n",
      "INFO:guidedlda:<1880> log likelihood: -146724\n",
      "INFO:guidedlda:<1900> log likelihood: -146750\n",
      "INFO:guidedlda:<1920> log likelihood: -146828\n",
      "INFO:guidedlda:<1940> log likelihood: -146744\n",
      "INFO:guidedlda:<1960> log likelihood: -146721\n",
      "INFO:guidedlda:<1980> log likelihood: -146828\n",
      "INFO:guidedlda:<1999> log likelihood: -146582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.17 s, sys: 236 ms, total: 9.41 s\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x7fa50086a160>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X, seed_topics=seed_topics, seed_confidence=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8097e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: food good spacious cramped service bit nice place staff great\n",
      "Topic 1: spacious nice good food place great service staff terrace coffee\n",
      "Topic 2: steep stairs food small place cramped delicious nice restaurant staff\n",
      "Topic 3: spacious nice good place food staff terrace great service delicious\n",
      "Topic 4: spacious good parking nice wheelchair amsterdam great garage accessible place\n"
     ]
    }
   ],
   "source": [
    "# Seeing the model output topics, and top 10 words per topic\n",
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1820d3",
   "metadata": {},
   "source": [
    "## Tagging the topics to create id - topic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num_name = {\"Topic 0\":\"general_acc_words\",\n",
    "                  \"Topic 1\":\"entrance_words\",\n",
    "                  \"Topic 2\":\"bathroom_words\",\n",
    "                  \"Topic 3\":\"space_words\",\n",
    "                  \"Topic 4\":\"stairs_words\"}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384848ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_topics(model_glda,X,num_topics,dataframe,col_name):\n",
    "    \"\"\"\n",
    "    A function which creates dataframe with documents, their dominant topic, along with their probabilities\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    model_glda - Guided LDA trained model\n",
    "    X - Document term frequency table\n",
    "    num_topics - Number of topics the model was trained for\n",
    "    dataframe - Dataframe consisting of cleaned text column\n",
    "    col_name - Column name in dataframe holding cleaned text\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    A dataframe with document number, topic, probability of topic\n",
    "    \"\"\"\n",
    "    df_doc_top = pd.DataFrame()\n",
    "    final_list = []\n",
    "    for index in range(len(dataframe[col_name])):\n",
    "        word_id_dict = dict((x,y) for x,y in zip([x for x in range(num_topics)],np.round(model.transform(X[index])*100,1).tolist()[0]))\n",
    "        word_score_list = []\n",
    "        for index in range(num_topics):\n",
    "            try:\n",
    "                value = word_id_dict[index]\n",
    "            except:\n",
    "                value = 0\n",
    "            word_score_list.append(value)\n",
    "        final_list.append(word_score_list)\n",
    "\n",
    "    df_doc_top = pd.DataFrame(final_list)\n",
    "    df_doc_top.columns = ['Topic ' + str(i) for i in range(num_topics)]\n",
    "    df_doc_top.index = ['Document ' + str(i) for i in range(len(dataframe[col_name]))]\n",
    "\n",
    "    df_doc_top[\"Dominant_Topic\"] = df_doc_top.idxmax(axis=1).tolist()\n",
    "    df_doc_top[\"Topic_Probability\"] = df_doc_top.max(axis=1).tolist()\n",
    "    document_df = df_doc_top.reset_index().rename(columns={\"index\":\"Document\"})[[\"Document\",\"Dominant_Topic\",\"Topic_Probability\"]]\n",
    "\n",
    "    return document_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df=get_doc_topics(model,X,5,df2,\"clean_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ca3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.concat([df2.Id,document_df.Dominant_Topic],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c145a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Dominant_Topic=submission.Dominant_Topic.replace(topic_num_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3078a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=submission.set_index(\"Id\").rename(columns={\"Dominant_Topic\":\"topic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
